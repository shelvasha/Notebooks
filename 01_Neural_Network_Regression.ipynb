{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Neural_Network_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uhMwcCMWbFdD",
        "qF0ZEAa4ZMhL",
        "aNBdKJePR5OK"
      ],
      "authorship_tag": "ABX9TyOPzS4EDyi0UupvqjUI4wrv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shelvasha/Notebooks/blob/main/01_Neural_Network_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhMwcCMWbFdD"
      },
      "source": [
        "### What's regression?\n",
        "* In stats modeling, regressions (analysis) is estimating the relationships between a dependent variable (often called the 'outcome variable') and one or more independent variables (often called 'predictors', 'covariates', or 'features')\n",
        "  * How much or how many\" of something.\n",
        "  * Predicting something from prior data (think slope.\n",
        "\n",
        "#### What's going to be covered in this notebook:\n",
        "\n",
        "* Architecture of a neural network regression model.\n",
        "* Input and output shapes of a regression model (features and labels).\n",
        "* Creating sutom data to view and fit.\n",
        "* Steps in modelling:\n",
        "    1. Create a model\n",
        "    2. Compile a model\n",
        "    3. Fit a model\n",
        "    4. Evaluate a model\n",
        "* Different evaluation methods\n",
        "* Saving and loading models\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF0ZEAa4ZMhL"
      },
      "source": [
        "### Architecture of regression inputs, outputs and shapes\n",
        "\n",
        "* Having understanding or intuition of the data, its input and shape and the effect that this has on the output and its shape, is probably the most important part of machine learning.\n",
        "*   A large portion of time focuses on the inputs, specifically the encoding of inputs.\n",
        "\n",
        "#### Anatomy of a Neural network in Tensorflow\n",
        "* Anatomically, neural networks consists of:\n",
        "1. Input layer\n",
        "2. Hidden layer\n",
        "3. Output layer\n",
        "4. Output layer shape\n",
        "\n",
        "And bonus parameters (more on those)\n",
        "4. Neurons per hidden layer\n",
        "5. Hidden activation\n",
        "6. Output activation\n",
        "7. Loss function\n",
        "8. Optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Epka3XRoLrK"
      },
      "source": [
        "## Introduction to Regression with Neural Networks in TensorFlow\n",
        "\n",
        "There are many definititons for a regression problem, but in our case we are going to simplify it: predicting a numerical value based on some other combination of variables, even shorter... predicting a number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxmOZ2_Wnowc",
        "outputId": "c29918e0-1a74-43a2-d09f-6d0fd0870f77"
      },
      "source": [
        "# Import Tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7mzkJUPoq-0"
      },
      "source": [
        "### Creating data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "7cwwM_2Yo3K4",
        "outputId": "8a0653bb-3acd-4990-a7b5-51e5ef50b4bc"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.,-4.,-1.,2.,5.,8.,11.,14.])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.,6.,9.,12.,15.,18.,21.,24.])\n",
        "\n",
        "# Visualize\n",
        "plt.scatter(X,y)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fda64ee3650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzfrwZD4pds6",
        "outputId": "ddde4def-791f-4bf8-c3d0-3d365b741dbc"
      },
      "source": [
        "# Turn our NumPy arrays into tensors\n",
        "\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "\n",
        "X.shape,y.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([8]), TensorShape([8]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nib1Jbe3zRQ6"
      },
      "source": [
        "# Steps in modeling with TensorFlow\n",
        "1. **Creating a model** - define the input and output layers.\n",
        "2. **Compiling a model** - define the loss function\n",
        "3. Fitting a model - letting the model try to find patterns between X & y (features and labels) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrXPOa5wz9AY",
        "outputId": "037bf74b-41c0-4627-9a9e-96f731347fa7"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model using the Sequential API\n",
        "# A Sequential model is appropriate for a plain stack of\n",
        "# layers where each layer has exactly one input tensor and one output tensor.\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=tf.keras.losses.mae, # mae is short for mean absolute error. \n",
        "              optimizer=tf.keras.optimizers.SGD(), #short for stochastic gradient descent\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X,y, epochs=5)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 20.6214 - mae: 20.6214\n",
            "Epoch 2/5\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5004 - mae: 10.5004\n",
            "Epoch 3/5\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 14.5408 - mae: 14.5408\n",
            "Epoch 4/5\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1988 - mae: 10.1988\n",
            "Epoch 5/5\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 14.8556 - mae: 14.8556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fda5d475550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kiov9LwaELkt",
        "outputId": "b8e29538-e4c7-4b05-ac6b-a8c5803dc5a3"
      },
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "          76,   80,   84,   88,   92,   96], dtype=int32)>,\n",
              " <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpvNrXC8EOou",
        "outputId": "6aaf0963-8182-4f0d-ab7d-54e9bbfc19e7"
      },
      "source": [
        "# Try and make a prediction using the model\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fda56fbd830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[13.3044195]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPC3r74YFFUn"
      },
      "source": [
        "### Model Improvement\n",
        "\n",
        "- We have a model and we've fit data to it and made a prediction.... but it isn't great.\n",
        "- How do we improve the model?\n",
        "  - We can improve the model by tweaking the steps we took to create the model in the first place.\n",
        "  - In this case, that would be:\n",
        "    1. Increasing the number of hidden units (neurons) within each hidden layer.\n",
        "    2. Changing the optimization function or perhaps the learning rate.\n",
        "    3. Fit the model using more epochs, so give the model more data or chances to fit the model to the data better. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxpU56f0E8TQ",
        "outputId": "1afdc708-6c14-4bdb-9d48-b302e386e343"
      },
      "source": [
        "# Let's rebuild the model\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model using the Sequential API\n",
        "# A Sequential model is appropriate for a plain stack of\n",
        "# layers where each layer has exactly one input tensor and one output tensor.\n",
        "\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=\"mae\", optimizer=\"sgd\", metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model (this time we'll train for longer)\n",
        "model.fit(X,y, epochs=100)\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.6214 - mae: 20.6214\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 10.5004 - mae: 10.5004\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.5408 - mae: 14.5408\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1988 - mae: 10.1988\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.8556 - mae: 14.8556\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.0283 - mae: 12.0283\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 9.2358 - mae: 9.2358\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 13.6569 - mae: 13.6569\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.9578 - mae: 13.9578\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9240 - mae: 9.9240\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8897 - mae: 9.8897\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8389 - mae: 9.8389\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 9.7677 - mae: 9.7677\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.5921 - mae: 10.5921\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.9629 - mae: 13.9629\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 13.2113 - mae: 13.2113\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0768 - mae: 10.0768\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.1545 - mae: 10.1545\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.9780 - mae: 9.9780\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6596 - mae: 12.6596\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 13.3684 - mae: 13.3684\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6291 - mae: 9.6291\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3805 - mae: 9.3805\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6433 - mae: 9.6433\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 9.6271 - mae: 9.6271\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2780 - mae: 9.2780\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.6878 - mae: 9.6878\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.5894 - mae: 9.5894\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4806 - mae: 9.4806\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6878 - mae: 9.6878\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.1984 - mae: 14.1984\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.6523 - mae: 9.6523\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 9.5368 - mae: 9.5368\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8250 - mae: 9.8250\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 10.2169 - mae: 10.2169\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 9.5332 - mae: 9.5332\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 9.4343 - mae: 9.4343\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 9.6817 - mae: 9.6817\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.8572 - mae: 9.8572\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.9118 - mae: 11.9118\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9303 - mae: 9.9303\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.3724 - mae: 9.3724\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1179 - mae: 9.1179\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5566 - mae: 9.5566\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4622 - mae: 9.4622\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1347 - mae: 9.1347\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0546 - mae: 9.0546\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.6906 - mae: 8.6906\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.8250 - mae: 10.8250\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.8602 - mae: 8.8602\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.3575 - mae: 10.3575\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.7236 - mae: 15.7236\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.6233 - mae: 8.6233\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5043 - mae: 9.5043\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4514 - mae: 9.4514\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.2619 - mae: 12.2619\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.3216 - mae: 16.3216\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.4799 - mae: 15.4799\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.8017 - mae: 15.8017\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6969 - mae: 12.6969\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.6114 - mae: 13.6114\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4435 - mae: 9.4435\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.8731 - mae: 11.8731\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5873 - mae: 9.5873\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.9927 - mae: 8.9927\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.8681 - mae: 8.8681\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0978 - mae: 9.0978\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.1582 - mae: 9.1582\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.1691 - mae: 9.1691\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1993 - mae: 9.1993\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0263 - mae: 9.0263\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0357 - mae: 10.0357\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 12.3106 - mae: 12.3106\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4836 - mae: 8.4836\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7841 - mae: 8.7841\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.8676 - mae: 8.8676\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.2194 - mae: 8.2194\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.1691 - mae: 11.1691\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.1225 - mae: 9.1225\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.6439 - mae: 13.6439\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.2508 - mae: 14.2508\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.0181 - mae: 17.0181\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 9.4761 - mae: 9.4761\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.5988 - mae: 8.5988\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7685 - mae: 8.7685\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.9465 - mae: 8.9465\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1053 - mae: 9.1053\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 8.7563 - mae: 8.7563\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.8539 - mae: 8.8539\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.6972 - mae: 8.6972\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.7054 - mae: 8.7054\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.5940 - mae: 8.5940\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 8.9756 - mae: 8.9756\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6713 - mae: 9.6713\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.9296 - mae: 12.9296\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.0265 - mae: 9.0265\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.2358 - mae: 10.2358\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 14.5951 - mae: 14.5951\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6355 - mae: 10.6355\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.8704 - mae: 15.8704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fda5d54eb10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHuQM7pUJPlx",
        "outputId": "8f82ead8-17fa-4943-8eb3-c4fbf0aa993c"
      },
      "source": [
        "# Let's remind ourselves of the data again\n",
        "X, y"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "          76,   80,   84,   88,   92,   96], dtype=int32)>,\n",
              " <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHpXchS7JToI",
        "outputId": "adbeb361-b9af-4833-ee33-2c05b84612db"
      },
      "source": [
        "# Let's see if the model has improved\n",
        "model.predict([17.0])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fda581bc9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16.654217]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgWl-UDHL94n",
        "outputId": "a3abb1d9-ff8f-4b3f-9b1e-77e357fbe025"
      },
      "source": [
        "# We can do better than that. Let's increase the number of neurons and see where we are end up\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model using the Sequential API\n",
        "# A Sequential model is appropriate for a plain stack of\n",
        "# layers where each layer has exactly one input tensor and one output tensor.\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=\"mae\", optimizer=\"sgd\", metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model again\n",
        "model.fit(X,y, epochs=100)\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 42.8156 - mae: 42.8156\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.7016 - mae: 5.7016\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.7998 - mae: 14.7998\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.5882 - mae: 14.5882\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.7802 - mae: 10.7802\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.3618 - mae: 17.3618\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9411 - mae: 9.9411\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 15.6830 - mae: 15.6830\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.9220 - mae: 23.9220\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.7834 - mae: 10.7834\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.4307 - mae: 12.4307\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6559 - mae: 12.6559\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.0973 - mae: 14.0973\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.5574 - mae: 17.5574\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.7626 - mae: 13.7626\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.6333 - mae: 11.6333\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.7509 - mae: 11.7509\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6613 - mae: 10.6613\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.3276 - mae: 11.3276\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.5918 - mae: 12.5918\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.1650 - mae: 15.1650\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.7630 - mae: 13.7630\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 12.8993 - mae: 12.8993\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2091 - mae: 9.2091\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6181 - mae: 12.6181\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.8813 - mae: 12.8813\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.1900 - mae: 11.1900\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.8124 - mae: 8.8124\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.4804 - mae: 17.4804\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.2515 - mae: 12.2515\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7140 - mae: 13.7140\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.8769 - mae: 14.8769\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.0680 - mae: 8.0680\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.4283 - mae: 8.4283\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.9141 - mae: 14.9141\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0339 - mae: 10.0339\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.4210 - mae: 10.4210\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.9791 - mae: 9.9791\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.7118 - mae: 9.7118\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 13.1711 - mae: 13.1711\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.8025 - mae: 13.8025\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.5602 - mae: 13.5602\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.5593 - mae: 10.5593\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.7673 - mae: 10.7673\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.2285 - mae: 13.2285\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.8427 - mae: 16.8427\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.9551 - mae: 11.9551\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.4002 - mae: 10.4002\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1678 - mae: 10.1678\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.3445 - mae: 21.3445\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.8291 - mae: 12.8291\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.3440 - mae: 15.3440\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 7.8090 - mae: 7.8090\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.4854 - mae: 13.4854\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.4969 - mae: 15.4969\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.3554 - mae: 12.3554\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.7993 - mae: 12.7993\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.3708 - mae: 13.3708\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.7648 - mae: 11.7648\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.0614 - mae: 11.0614\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.0088 - mae: 12.0088\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.8357 - mae: 10.8357\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.4028 - mae: 7.4028\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.4056 - mae: 11.4056\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.8062 - mae: 17.8062\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9538 - mae: 7.9538\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.2020 - mae: 8.2020\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1699 - mae: 9.1699\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.6363 - mae: 14.6363\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.7431 - mae: 16.7431\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.2262 - mae: 14.2262\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.6742 - mae: 13.6742\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0409 - mae: 10.0409\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6865 - mae: 7.6865\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.2435 - mae: 14.2435\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6314 - mae: 12.6314\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.2291 - mae: 11.2291\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.1982 - mae: 15.1982\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 7.9713 - mae: 7.9713\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.0793 - mae: 5.0793\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.7784 - mae: 8.7784\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.6865 - mae: 14.6865\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.7964 - mae: 9.7964\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.3447 - mae: 6.3447\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.1447 - mae: 14.1447\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.2096 - mae: 15.2096\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.2277 - mae: 12.2277\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.4304 - mae: 15.4304\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.2842 - mae: 11.2842\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.0488 - mae: 16.0488\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.4028 - mae: 16.4028\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9668 - mae: 14.9668\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.2162 - mae: 15.2162\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4245 - mae: 11.4245\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.9152 - mae: 10.9152\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.2940 - mae: 7.2940\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 13.9688 - mae: 13.9688\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.2277 - mae: 14.2277\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0207 - mae: 10.0207\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.3111 - mae: 8.3111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fda5d501ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA9NRpKFODMr",
        "outputId": "689af6ae-cc8f-4c24-e4d0-cc0c6e0a72ec"
      },
      "source": [
        "# Try predicting again\n",
        "model.predict([17.0])"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fda5f9ff710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[13.61597]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0kjULxxO63x"
      },
      "source": [
        "#### In practice, not all changes improve the model\n",
        "- In case 2, the model was better than the original after changing the the number of epochs taken to train the model.\n",
        "- In case 3, the model performed worse by increasing the neuron (Dense) layers.\n",
        "- How about the optimizer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bblCUyfGOHf5",
        "outputId": "36aa0c6a-1427-4ec6-9fa6-37dc9aafef8c"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model using the Sequential API\n",
        "# A Sequential model is appropriate for a plain stack of\n",
        "# layers where each layer has exactly one input tensor and one output tensor.\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=\"mae\", optimizer=tf.keras.optimizers.Adam(lr=0.01), metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model again\n",
        "model.fit(X,y, epochs=100)\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 46.8201 - mae: 46.8201\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 32.1082 - mae: 32.1082\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.2902 - mae: 22.2902\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.9259 - mae: 9.9259\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3159 - mae: 7.3159\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.9177 - mae: 11.9177\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.6374 - mae: 11.6374\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4021 - mae: 8.4021\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.6909 - mae: 4.6909\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7081 - mae: 6.7081\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.6041 - mae: 8.6041\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1255 - mae: 8.1255\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6614 - mae: 5.6614\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 4.6664 - mae: 4.6664\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.4847 - mae: 5.4847\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2621 - mae: 6.2621\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.0131 - mae: 5.0131\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.9898 - mae: 3.9898\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.5531 - mae: 4.5531\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.8639 - mae: 4.8639\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.8318 - mae: 3.8318\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.1144 - mae: 4.1144\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.0924 - mae: 4.0924\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.8549 - mae: 3.8549\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.5803 - mae: 3.5803\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.9844 - mae: 3.9844\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5549 - mae: 3.5549\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.5566 - mae: 3.5566\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.6682 - mae: 3.6682\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.5654 - mae: 3.5654\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.2242 - mae: 3.2242\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3813 - mae: 3.3813\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.3358 - mae: 3.3358\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.2297 - mae: 3.2297\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3816 - mae: 3.3816\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.2835 - mae: 3.2835\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.0427 - mae: 3.0427\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.0505 - mae: 3.0505\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.0092 - mae: 3.0092\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.2077 - mae: 3.2077\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.0390 - mae: 3.0390\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.8690 - mae: 2.8690\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.8959 - mae: 2.8959\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.9107 - mae: 2.9107\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.8175 - mae: 2.8175\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.7921 - mae: 2.7921\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.7035 - mae: 2.7035\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7904 - mae: 2.7904\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.9040 - mae: 2.9040\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.5382 - mae: 2.5382\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.8301 - mae: 2.8301\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.5369 - mae: 2.5369\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.5000 - mae: 2.5000\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.5563 - mae: 2.5563\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.2501 - mae: 2.2501\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.3379 - mae: 2.3379\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.1355 - mae: 2.1355\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.1546 - mae: 2.1546\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.0082 - mae: 2.0082\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.0101 - mae: 2.0101\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.0293 - mae: 2.0293\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.8793 - mae: 1.8793\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.9747 - mae: 1.9747\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.1191 - mae: 2.1191\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.7604 - mae: 1.7604\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.5593 - mae: 1.5593\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.5992 - mae: 1.5992\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.7391 - mae: 1.7391\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.4373 - mae: 1.4373\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.5422 - mae: 1.5422\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.4575 - mae: 1.4575\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.7137 - mae: 1.7137\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4439 - mae: 1.4439\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4467 - mae: 1.4467\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8425 - mae: 0.8425\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1981 - mae: 1.1981\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6469 - mae: 0.6469\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0159 - mae: 1.0159\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0563 - mae: 1.0563\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0511 - mae: 1.0511\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.6668 - mae: 1.6668\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5229 - mae: 0.5229\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7946 - mae: 0.7946\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8023 - mae: 0.8023\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4825 - mae: 0.4825\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9447 - mae: 0.9447\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2914 - mae: 1.2914\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5372 - mae: 0.5372\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.6146 - mae: 1.6146\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.4337 - mae: 1.4337\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.8697 - mae: 1.8697\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.5819 - mae: 1.5819\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0947 - mae: 1.0947\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5570 - mae: 0.5570\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3874 - mae: 0.3874\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6944 - mae: 0.6944\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4457 - mae: 0.4457\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.2930 - mae: 0.2930\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3748 - mae: 0.3748\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8512 - mae: 0.8512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fda581e7890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNBdKJePR5OK"
      },
      "source": [
        "### Takeaways\n",
        "- Optimizer changes and altering the learning rate had the ***most profound*** effect on the model improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceWx3A5cSKXx"
      },
      "source": [
        "### Evaluating a model\n",
        "\n",
        "- In practice, the typical workflow of building a model:\n",
        "  1. Create a model\n",
        "  2. Fit it\n",
        "  3. Evaluate it\n",
        "  4. Tweak the model\n",
        "  5. Repeat steps 2-4.\n",
        "\n",
        "#### When it comes to evaluation, **visualize, visualize, visualize**.\n",
        "- It's good to visualize the data - what kind of data are we looking at?\n",
        "- The model itself - what does the model look like?\n",
        "- The training of the model - how does the model perform while it learns?\n",
        "- Predictions of the model - how well do the predictions line up with truth?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZjDnll9Twnf",
        "outputId": "588d4a21-b4cd-478b-8684-4b2abc88270d"
      },
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100,100,4)\n",
        "X"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDvIRuGBT5-I",
        "outputId": "7f8dcfc9-dab3-4ca4-dc65-8c1ca4bb77bb"
      },
      "source": [
        "# Make labels for the dataset\n",
        "y = X + 10\n",
        "y"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "zaom3jxAUDBe",
        "outputId": "172fc03c-7bdd-4d16-ce12-9fbed2ac062f"
      },
      "source": [
        "# Visualize\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X,y)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fda5d95ff90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8UJzgXhUnEB"
      },
      "source": [
        "### The Three Sets\n",
        "- **Training set** - Course materials\n",
        "- **Validation set** - Practice test\n",
        "- **Test set** - The test\n",
        "\n",
        "The whole point of this is generalization so that the model can perform well on data it hasn't seen before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWrsKyY9VYrV",
        "outputId": "c1c1a636-9ead-4581-dc04-481403e251d0"
      },
      "source": [
        "# Check length of how many samples we have\n",
        "len(X)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdV9HbLqVdxu",
        "outputId": "69c674fb-9c69-48dc-b4f5-4b53829ecf8c"
      },
      "source": [
        "# Split the data into training and test sets\n",
        "X_train = X[:40]\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:]\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fciAHOlWhQB"
      },
      "source": [
        "### Visualizing the data again\n",
        "- Now that we've got our data split into training and test sets, let's visualize again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "yXj0kLrTWp_F",
        "outputId": "d05ff313-2429-4f6e-cf06-e059c1c59271"
      },
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(X_train,y_train, c=\"b\", label=\"Training data\") # Our model is learning on this data \n",
        "plt.scatter(X_test,y_test, c=\"g\", label=\"Testing data\")\n",
        "plt.legend();"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruzXGLwtXIHw",
        "outputId": "c7400139-4402-4593-e14a-98e376b00c1c"
      },
      "source": [
        "# Build a neural network with the training data\n",
        "model = tf.keras.Sequential([\n",
        "                  tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
        "                  tf.keras.layers.Dense(1, name=\"output_layer\")], name=\"Example_Model\")\n",
        "\n",
        "# The new parameter (input_shape) passes a default shape (tensor) of the data\n",
        "# in order to summarize the model prior to fitting.\n",
        "\n",
        "model.compile(loss=\"mae\", optimizer=tf.keras.optimizers.Adam(lr=0.01), metrics=[\"mae\"])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=0)\n",
        "#model.summary()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fda605346d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siHlVFhtYuLR"
      },
      "source": [
        "- Total parameters - total number of parameters in the model.\n",
        "- Trainable parameters - the parameters in the model that can update as it trains.\n",
        "- Non-trainable parameters - these are parameters that aren't updated during training (typical in already learned patterns or parameters e.g. **transfer learning**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsJR0m6ke2SX"
      },
      "source": [
        "# Plotting the model\n",
        "#from tensorflow.keras.utils import plot_model\n",
        "#plot_model(model=model, show_shapes=True)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GHUT8ONhINW"
      },
      "source": [
        "### Visualizing a model's predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMpvziFRiyd-",
        "outputId": "9935f91a-418d-4732-f32d-54100e9aaaba"
      },
      "source": [
        "# Make Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Plot the predictions - Let's do a function to save time in the future\n",
        "def plot_pred (train_data=X_train,\n",
        "               train_labels=y_train,\n",
        "               test_data=X_test,\n",
        "               test_labels=y_test,\n",
        "               predictions=y_pred):\n",
        "  plt.figure(figsize=(10,7))\n",
        "  plt.scatter(train_data,train_labels, c=\"b\", label=\"Training data\")\n",
        "  plt.scatter(test_data,test_labels, c=\"g\", label=\"Testing data\")\n",
        "  plt.scatter(test_data,predictions, c=\"r\", label=\"Predictions\")\n",
        "  plt.legend();"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fda609b7a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "cQANg32jn8DV",
        "outputId": "b4a763eb-8c3e-49f3-a2cf-65e71e963906"
      },
      "source": [
        "plot_pred() # Not great initially but much better when increasing the learning rate."
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7EkiYWfpEuu"
      },
      "source": [
        "### Evaluating model predictions with regression evaluation metrics\n",
        "\n",
        "- Mean Absolute Error\n",
        "- Mean square Error\n",
        "- Huber"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naTX1gJerXvU",
        "outputId": "0cb6a9c4-e9f7-4b27-99ef-dce7677ba2f5"
      },
      "source": [
        "# Evaluate the model on the test set\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 89ms/step - loss: 0.7175 - mae: 0.7175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7175437808036804, 0.7175437808036804]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X5Nsuvlrf7X",
        "outputId": "7fb15318-aafa-4652-f346-d13c68f83075"
      },
      "source": [
        "# MAE\n",
        "tf.keras.losses.MAE(y_test, tf.squeeze(y_pred))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.7175423>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgeIIlisusn4",
        "outputId": "96bb6ee5-967a-464e-d5dd-c7986fd00f5a"
      },
      "source": [
        "# MSE\n",
        "tf.keras.losses.MSE(y_test, tf.squeeze(y_pred))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5252059>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    }
  ]
}